# Repo2Doc

A LangGraph-based tool for reverse-engineering requirements documentation from codebases.

## Overview

Repo2Doc is a tool that uses Large Language Models (LLMs) to automatically generate requirements specification documents from code repositories. It draws inspiration from [swark](https://github.com/swark-io/swark)'s design philosophy, implementing features like file filtering, code chunking, and incremental document generation.

### Key Features

- ðŸ” **Smart File Filtering**: Support for extension-based inclusion and pattern-based exclusion
- ðŸ“¦ **Auto Chunking**: Automatic chunking based on LLM token limits
- ðŸ”„ **Incremental Generation**: Each chunk's output is merged with the previous document
- ðŸ“Š **Detailed Reports**: Generates processing reports and intermediate results
- âš™ï¸ **Flexible Configuration**: YAML configuration file support

## Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Input Repo    â”‚
â”‚      Path       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Scan Files  â”‚  Scan directory, get all files
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Filter Files â”‚  Filter by extension and exclude patterns
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Chunk Files  â”‚  Chunk by token limit
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Generate Doc â”‚  LLM incremental generation
â”‚    (loop)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Save Output  â”‚  Save document and report
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Installation

### Using uv (Recommended)

```bash
cd repo2doc
uv sync
```

### Using pip

```bash
pip install -e .
```

## Configuration

### Environment Variables

Create a `.env` file:

```bash
cp .env.example .env
```

Edit the `.env` file to set your API key:

```bash
OPENAI_API_KEY="your-api-key-here"

# Optional: Custom API base URL
# OPENAI_BASE_URL="https://api.openai.com/v1"
```

### Configuration File

Edit `config.yaml` to customize settings:

```yaml
# File filter configuration
file_filter:
  include_extensions:
    - ".py"
    - ".js"
    - ".ts"
  exclude_patterns:
    - "**/node_modules/**"
    - "**/__pycache__/**"
  max_file_size: 102400  # 100KB
  max_files: 500

# LLM configuration
llm:
  model: "gpt-4o"
  temperature: 0.3
  max_input_tokens: 100000
  reserved_tokens: 10000

# Output configuration
output:
  output_dir: "./repo2doc-output"
  filename: "requirements.md"
  save_intermediate: true
```

## Usage

### Command Line

```bash
# Use default configuration
uv run python main.py /path/to/repo

# Use custom configuration
uv run python main.py /path/to/repo -c config.yaml

# Show verbose logs
uv run python main.py /path/to/repo -v
```

### Python API

```python
from llm_workflow import run_workflow

# Run workflow
final_state = run_workflow(
    repo_path="/path/to/repo",
    config_path="config.yaml"
)

# Check result
if final_state["status"] == "completed":
    print("Document generated successfully!")
    print(f"Output: {final_state['current_document'][:500]}...")
else:
    print(f"Generation failed: {final_state['error']}")
```

## Output

After running, a `repo2doc-output/` folder will be created in the repository directory:

```
repo2doc-output/
â”œâ”€â”€ requirements.md           # Final requirements document
â”œâ”€â”€ 2024-01-01_12-00-00_requirements.md  # Timestamped backup
â”œâ”€â”€ 2024-01-01_12-00-00_report.md        # Processing report
â””â”€â”€ intermediate/             # Intermediate results (if enabled)
    â”œâ”€â”€ chunk_1.md
    â”œâ”€â”€ chunk_2.md
    â””â”€â”€ ...
```

## Project Structure

```
repo2doc/
â”œâ”€â”€ main.py              # Main entry point
â”œâ”€â”€ llm_workflow.py      # LangGraph workflow definition
â”œâ”€â”€ state.py             # State management
â”œâ”€â”€ config_loader.py     # Configuration loader
â”œâ”€â”€ config.yaml          # Default configuration
â”œâ”€â”€ nodes/               # Workflow nodes
â”‚   â”œâ”€â”€ node1_scan_files.py
â”‚   â”œâ”€â”€ node2_filter_files.py
â”‚   â”œâ”€â”€ node3_chunk_files.py
â”‚   â”œâ”€â”€ node4_generate_doc.py
â”‚   â””â”€â”€ node5_save_output.py
â”œâ”€â”€ utils/               # Utility functions
â”‚   â”œâ”€â”€ token_counter.py
â”‚   â””â”€â”€ file_utils.py
â”œâ”€â”€ tests/               # Tests
â”‚   â””â”€â”€ test_workflow.py
â”œâ”€â”€ pyproject.toml       # Project configuration
â”œâ”€â”€ .env.example         # Environment variables example
â”œâ”€â”€ readme.cn.md         # Chinese documentation
â””â”€â”€ readme.en.md         # English documentation
```

## Technical Principles

### Incremental Document Generation

Since codebases may exceed LLM context limits, Repo2Doc uses an incremental generation strategy:

1. **Initial Generation**: Generate initial document using the first code chunk
2. **Incremental Update**: Subsequent chunks are input to LLM along with the previous document
3. **Merge Strategy**: LLM merges newly discovered features into the existing document

```
Chunk 1 â†’ Document v1
Chunk 2 + Document v1 â†’ Document v2
Chunk 3 + Document v2 â†’ Document v3
...
Chunk N + Document v(N-1) â†’ Final Document
```

### Chunking Strategy

```python
# Calculate max tokens per chunk
max_tokens_per_chunk = max_input_tokens - reserved_tokens

# Add files to current chunk sequentially
for file in files:
    if current_tokens + file_tokens > max_tokens_per_chunk:
        # Create new chunk
        save_current_chunk()
        start_new_chunk()
    add_file_to_chunk(file)
```

## Comparison with swark

| Feature | Repo2Doc | swark |
|---------|----------|-------|
| **Output Type** | Requirements Doc | Architecture Diagram |
| **LLM Framework** | LangGraph | VS Code API |
| **Chunking Strategy** | Incremental Update | Truncation |
| **File Filtering** | Similar | Similar |
| **Runtime Environment** | CLI/Python | VS Code Extension |

## License

MIT License
